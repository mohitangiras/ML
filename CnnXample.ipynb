{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CnnXample.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNPD2HVkFqXaIl3Yzl99qiP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohitangiras/ML/blob/master/CnnXample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKfic27iceTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQELrvvcW6eH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow.keras import datasets, layers, models, optimizers \n",
        "# network and training \n",
        "EPOCHS = 5 \n",
        "BATCH_SIZE = 128 \n",
        "VERBOSE = 1 \n",
        "OPTIMIZER = tf.keras.optimizers.Adam() \n",
        "VALIDATION_SPLIT=0.95 \n",
        "IMG_ROWS, IMG_COLS = 28, 28 \n",
        "# input image dimensions \n",
        "INPUT_SHAPE = (IMG_ROWS, IMG_COLS, 1) \n",
        "NB_CLASSES = 10 \n",
        "# number of outputs = number of digits"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOkzkOqnYzBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgXTyKAZYzSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onO096ikXfpT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "1eb8aa30-4c5f-43ec-e70a-636448ff47cd"
      },
      "source": [
        "def build(input_shape, classes): \n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Convolution2D(20, (5, 5), activation='relu', input_shape=input_shape)) \n",
        "  model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "  model.add(layers.Convolution2D(50, (5, 5), activation='relu')) \n",
        "  model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "  # Flatten => RELU layers \n",
        "  model.add(layers.Flatten()) \n",
        "  model.add(layers.Dense(500, activation='relu')) # a softmax classifier \n",
        "  model.add(layers.Dense(classes, activation=\"softmax\")) \n",
        "  return model\n",
        "\n",
        "# data: shuffled and split between train and test sets \n",
        "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data() \n",
        "# reshape \n",
        "X_train = X_train.reshape((60000, 28, 28, 1)) \n",
        "X_test = X_test.reshape((10000, 28, 28, 1)) \n",
        "# normalize \n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0 \n",
        "# cast \n",
        "X_train = X_train.astype('float32') \n",
        "X_test = X_test.astype('float32') \n",
        "# convert class vectors to binary class matrices \n",
        "y_train = tf.keras.utils.to_categorical(y_train, NB_CLASSES) \n",
        "y_test = tf.keras.utils.to_categorical(y_test, NB_CLASSES) \n",
        "# initialize the optimizer and model \n",
        "model = build(input_shape=INPUT_SHAPE, classes=NB_CLASSES) \n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER, metrics=[\"accuracy\"]) \n",
        "model.summary() # use TensorBoard, princess Aurora! \n",
        "callbacks = [ \n",
        "             # Write TensorBoard logs to './logs' directory \n",
        "             tf.keras.callbacks.TensorBoard(log_dir='./logs') \n",
        "] \n",
        "# fit \n",
        "history = model.fit(X_train, y_train, batch_size=BATCH_SIZE\n",
        "                    , epochs=EPOCHS, verbose=VERBOSE\n",
        "                    , validation_split=VALIDATION_SPLIT\n",
        "                    ,callbacks=callbacks) \n",
        "score = model.evaluate(X_test, y_test, verbose=VERBOSE) \n",
        "print(\"\\nTest score:\", score[0]) \n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 24, 24, 20)        520       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 12, 12, 20)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 8, 8, 50)          25050     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 4, 4, 50)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 500)               400500    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                5010      \n",
            "=================================================================\n",
            "Total params: 431,080\n",
            "Trainable params: 431,080\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            " 1/24 [>.............................] - ETA: 0s - loss: 2.3153 - accuracy: 0.0938WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            "24/24 [==============================] - 15s 606ms/step - loss: 1.2036 - accuracy: 0.6530 - val_loss: 0.4799 - val_accuracy: 0.8470\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 14s 599ms/step - loss: 0.3563 - accuracy: 0.8943 - val_loss: 0.3070 - val_accuracy: 0.9069\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 14s 596ms/step - loss: 0.2178 - accuracy: 0.9393 - val_loss: 0.2250 - val_accuracy: 0.9315\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 14s 596ms/step - loss: 0.1447 - accuracy: 0.9567 - val_loss: 0.1812 - val_accuracy: 0.9433\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 15s 606ms/step - loss: 0.1060 - accuracy: 0.9733 - val_loss: 0.1514 - val_accuracy: 0.9535\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1353 - accuracy: 0.9572\n",
            "\n",
            "Test score: 0.13534988462924957\n",
            "Test accuracy: 0.9571999907493591\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}